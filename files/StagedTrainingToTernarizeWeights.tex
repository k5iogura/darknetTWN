\documentclass[twocolumn]{article}
\usepackage[dvipdfmx]{graphicx}
\begin{document}

\title{Staged Training Method to ternarize neural network weights}
\author{Kenji Ogura}
\date{}
\maketitle

\section{Abstract}
I propose the staged training method(STM) for ternary weights network.
I show mAP performance of full ternarized weights network against full precision network.
Ternarization method is reffered to related work[2] and training algorithm is reffered to related work[3].
Proposed STM expands the method in related work[1].
I use VOC dataset as estimation dataset.
Full ternarized yolov2 with STM perform 73.82\% mAP against full precision's 76.85\% mAP  3.0\% dorps.
Full ternarized yolov3 with STM perform 71.26\% mAP against full precision's 75.54\% mAP 4.3\% dorps.
The result denotes that full ternary weights network is usefull for small computing device.

\section{Introduction}

For small device or Embedded systems without GPU, realtime object detection task via neural networks should be worked.
I was inspired below papers,
\begin{itemize}
\item
 Training a Binary Weight Object Detector by Knowledge Transfer for Autonomous Driving[1]
\item
 Ternary weight networks[2]
\item
 XNOR-Net: ImageNet Classification Using BinaryConvolutional Neural Networks[3]
\end{itemize}

Generally the inference task using full ternary weights -1,0,+1 is considered as low accuracy than full precision weights.
But for mobile device such as raspberryPI small weights will be efficient one of choices.
Some quantinization methods for model weights are proposed now such as FP16, bfloat, fixed point 16bits, 8bit, ternary 2bits and XNor 1bit too.
I consider that re-training after quatinization of weights is needed.
In this paper I propose Staged Trainiing Method(STM) for full ternary weights network and show the result as mAP.

\section{Staged training method}
In this paper I propose the staged training for yolov2-voc.cfg, yolov3-voc.cfg on Darknet website[4].
You can get full ternarized weights within 3 points accuracy drops for yolov2, within 4.5 points accuracy dorops for yolov3 using this method.
2bits ternary weights representaion may be x16 smaller than 32bit floating point.

STM generates Ternarized weights for yolov2-voc, yolov3-voc.
This method sprits a training step into 4 stages. Staging Plan is below,

\begin{itemize}
\item Stage-0 : few layers without around of detector are ternarized(M0)
\item Stage-1 : 40\% of all layers are ternarized(M1)
\item Stage-2 : 90\% of all layers are ternarized(M2)
\item Stage-3 : full ternarized(M3)
\end{itemize}

Each stages import weights from previous stage, such as stage-2 weights from stage-1.
But stage-0(M0) imports usual full precision weights.
Figure.1 shows staging for yolov2-voc.cfg into 4 training stages, and Figure.2 for yolov3-voc.cfg.
On each figures 'F' denote full precision weights and 'T' denotes ternarized weights.
To estimate this staged training method I implement ternary keyword for each convolution layer in cfg file like 'ternary=1' and I also support ternarizing weights function and ternarized weights memory area in darknet framework.
To avoid local minimun problem via training ternarized model I sprit training into some steps.

\begin{figure}
\includegraphics[width=8cm]{yolov2-voc_Stages.png}
\caption{Staging for yolov2-voc.cfg}
\end{figure}

\begin{figure}
\includegraphics[width=8cm]{yolov3-voc_Stages.png}
\caption{Staging for yolov3-voc.cfg}
\end{figure}

I trained yolov2-voc.cfg on 4 jobs, and checked each loss curves on Excell graph.
And I use AlexeyAB[5] darknet to get mAP of experiments.

\section{Result of Training}

Tables denote the result of my staged training.
VOC 2012, 2007 Dataset is used with training and VOC 2007 for estimation of mAP.

\begin{table}[htbp]
 \centering
 \begin{tabular}{c|c|c|l}
  Stage & mAP & IOU & comments \\ \hline\hline
  -        & 76.85 & 54.67 & official Weights \\ \hline
  M0       & 77.09 & 57.04 & -                \\ \hline
  M1       & 76.44 & 56.18 & -                \\ \hline
  M2       & 75.06 & 57.71 & -                \\ \hline
  M3       & 73.82 & 54.90 & full ternary     \\ \hline\hline
 \end{tabular}
 \caption{result regard to yolov2}
 \label{tb:yolov2}
\end{table}

In Table.1 Iteration 41000(2000/class), steps x0.1 80\% 90\%, lr=0.001 at all stages

\begin{table}[htbp]
 \centering
 \begin{tabular}{c|c|c|l}
  Stage & mAP & IOU & comments \\ \hline\hline
  -        & 75.54 & 62.78 & FT from darknet53.conv.75 \\ \hline
  M0       & 75.02 & 63.04 & -                \\ \hline
  M1       & 73.69 & 63.75 & -                \\ \hline
  M2       & 73.76 & 63.54 & -                \\ \hline
  M3       & 71.26 & 61.61 & full ternary     \\ \hline\hline
 \end{tabular}
 \caption{result regard to yolov3}
 \label{tb:yolov3}
\end{table}

In Table.2 Iteration 100400(5000/class), steps x0.1 80\% 90\%, lr=0.001 at M0 and M1
Iteration 60400(3000/class), steps x0.1 80\% 90\%, lr=0.001 at M2 and M3.

\section{Conclusion}

If your applications using object detection task requires speed but not accuracy you can use full ternary weights network.
To get efficient ternary weights you can use staged training method in this paper.
Ternary weights is x16 smaller than fp32 representation.
Full ternary weights network performs accuracy within 4.5\% mAP drops with yolov2 or yolov3 network on darknet framework.

\begin{thebibliography}{99}
 \item Jiaolong Xu, Peng Wang, Heng Yangâ€¡and Antonio et.al.
 "Training a Binary Weight Object Detector byKnowledge Transfer for Auonomous Driving" https://arxiv.org/pdf/1804.06332.pdf
 \item Fengfu Li and Bo Zhang, Bin Liu "Ternary weight networks" https://arxiv.org/pdf/1605.04711.pdf
 \item ohammad Rastegari, Vicente Ordonez, Joseph Redmon, Ali Farhadi Allen Institute for AI, University of Washington
 "XNOR-Net: ImageNet Classification Using BinaryConvolutional Neural Networks" https://arxiv.org/pdf/1603.05279.pdf
 \item https://github.com/pjreddie/darknet
 \item https://github.com/AlexeyAB/darknet

\end{thebibliography}

\end{document}
